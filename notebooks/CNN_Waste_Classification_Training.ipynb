{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9792419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Packages\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fe982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import Required Libraries\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from google.colab import files\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download Dataset from Kaggle\n",
    "print(\"Downloading waste classification dataset...\")\n",
    "path = kagglehub.dataset_download(\"aashidutt3/waste-segregation-image-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Set paths for the dataset\n",
    "dataset_base_path = path\n",
    "train_data_path = os.path.join(dataset_base_path, \"Dataset\", \"train\")\n",
    "test_data_path = os.path.join(dataset_base_path, \"Dataset\", \"val\")\n",
    "\n",
    "print(f\"Training data path: {train_data_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814efb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Dataset Verification Function\n",
    "def verify_dataset_structure(base_path):\n",
    "    \"\"\"Verify and display the dataset structure\"\"\"\n",
    "    print(f\"Checking dataset structure at: {base_path}\")\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"‚ùå Path does not exist: {base_path}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"üìÅ Dataset structure:\")\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        level = root.replace(base_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:3]:  # Show first 3 files\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 3:\n",
    "            print(f\"{subindent}... and {len(files) - 3} more files\")\n",
    "    return True\n",
    "\n",
    "# Verify the dataset structure\n",
    "verify_dataset_structure(dataset_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ec7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Organize Dataset for Binary Classification\n",
    "def organize_binary_dataset_simple():\n",
    "    \"\"\"\n",
    "    Function to organize the nested dataset structure into standard binary classification format.\n",
    "    The dataset has: train/biodegradable/[subcategories] and train/non_biodegradable/[subcategories]\n",
    "    \"\"\"\n",
    "    # Create organized dataset structure\n",
    "    organized_path = \"/content/organized_dataset\"\n",
    "    \n",
    "    # Create directories\n",
    "    for split in ['train', 'validation']:\n",
    "        for category in ['Biodegradable', 'Non-Biodegradable']:\n",
    "            os.makedirs(f\"{organized_path}/{split}/{category}\", exist_ok=True)\n",
    "    \n",
    "    print(\"Organizing dataset...\")\n",
    "    total_moved = 0\n",
    "    \n",
    "    # The dataset structure is: Dataset/train/biodegradable/[subcategories] and Dataset/train/non_biodegradable/[subcategories]\n",
    "    train_source_path = os.path.join(dataset_base_path, \"Dataset\", \"train\")\n",
    "    val_source_path = os.path.join(dataset_base_path, \"Dataset\", \"val\")\n",
    "    \n",
    "    print(f\"Train source path: {train_source_path}\")\n",
    "    print(f\"Val source path: {val_source_path}\")\n",
    "    \n",
    "    # Process both train and validation sets from the original dataset\n",
    "    source_splits = [\n",
    "        (train_source_path, \"train_source\"),\n",
    "        (val_source_path, \"val_source\")\n",
    "    ]\n",
    "    \n",
    "    all_biodegradable_images = []\n",
    "    all_non_biodegradable_images = []\n",
    "    \n",
    "    # Collect all images from both train and val sets\n",
    "    for source_path, split_name in source_splits:\n",
    "        if os.path.exists(source_path):\n",
    "            print(f\"\\nProcessing {split_name}...\")\n",
    "            \n",
    "            # Process biodegradable subcategories\n",
    "            bio_path = os.path.join(source_path, \"biodegradable\")\n",
    "            if os.path.exists(bio_path):\n",
    "                for subcat in os.listdir(bio_path):\n",
    "                    subcat_path = os.path.join(bio_path, subcat)\n",
    "                    if os.path.isdir(subcat_path):\n",
    "                        images = [os.path.join(subcat_path, f) for f in os.listdir(subcat_path) \n",
    "                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                        all_biodegradable_images.extend(images)\n",
    "                        print(f\"  Found {len(images)} images in biodegradable/{subcat}\")\n",
    "            \n",
    "            # Process non-biodegradable subcategories\n",
    "            non_bio_path = os.path.join(source_path, \"non_biodegradable\")\n",
    "            if os.path.exists(non_bio_path):\n",
    "                for subcat in os.listdir(non_bio_path):\n",
    "                    subcat_path = os.path.join(non_bio_path, subcat)\n",
    "                    if os.path.isdir(subcat_path):\n",
    "                        images = [os.path.join(subcat_path, f) for f in os.listdir(subcat_path) \n",
    "                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                        all_non_biodegradable_images.extend(images)\n",
    "                        print(f\"  Found {len(images)} images in non_biodegradable/{subcat}\")\n",
    "    \n",
    "    print(f\"\\nTotal collected:\")\n",
    "    print(f\"  Biodegradable: {len(all_biodegradable_images)} images\")\n",
    "    print(f\"  Non-Biodegradable: {len(all_non_biodegradable_images)} images\")\n",
    "    \n",
    "    # Shuffle and split the combined data\n",
    "    random.shuffle(all_biodegradable_images)\n",
    "    random.shuffle(all_non_biodegradable_images)\n",
    "    \n",
    "    # Function to copy images to organized structure\n",
    "    def copy_images_to_split(image_list, target_class, split_ratio=0.8):\n",
    "        split_idx = int(split_ratio * len(image_list))\n",
    "        train_images = image_list[:split_idx]\n",
    "        val_images = image_list[split_idx:]\n",
    "        \n",
    "        copied_count = 0\n",
    "        \n",
    "        # Copy training images\n",
    "        for i, src_path in enumerate(train_images):\n",
    "            if os.path.exists(src_path):\n",
    "                # Create unique filename to avoid conflicts\n",
    "                filename = f\"{target_class.lower()}_{i:06d}_{os.path.basename(src_path)}\"\n",
    "                dst_path = os.path.join(organized_path, 'train', target_class, filename)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                copied_count += 1\n",
    "        \n",
    "        # Copy validation images\n",
    "        for i, src_path in enumerate(val_images):\n",
    "            if os.path.exists(src_path):\n",
    "                # Create unique filename to avoid conflicts\n",
    "                filename = f\"{target_class.lower()}_val_{i:06d}_{os.path.basename(src_path)}\"\n",
    "                dst_path = os.path.join(organized_path, 'validation', target_class, filename)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                copied_count += 1\n",
    "        \n",
    "        return len(train_images), len(val_images), copied_count\n",
    "    \n",
    "    # Copy biodegradable images\n",
    "    bio_train, bio_val, bio_copied = copy_images_to_split(all_biodegradable_images, \"Biodegradable\")\n",
    "    print(f\"‚úÖ Biodegradable: {bio_train} train, {bio_val} validation ({bio_copied} copied)\")\n",
    "    \n",
    "    # Copy non-biodegradable images\n",
    "    non_bio_train, non_bio_val, non_bio_copied = copy_images_to_split(all_non_biodegradable_images, \"Non-Biodegradable\")\n",
    "    print(f\"‚úÖ Non-Biodegradable: {non_bio_train} train, {non_bio_val} validation ({non_bio_copied} copied)\")\n",
    "    \n",
    "    total_moved = bio_copied + non_bio_copied\n",
    "    print(f\"\\nTotal images organized: {total_moved}\")\n",
    "    return organized_path\n",
    "\n",
    "# Execute the organization\n",
    "organized_path = organize_binary_dataset_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Verify Organized Dataset\n",
    "def verify_organized_dataset(organized_path):\n",
    "    \"\"\"Verify the organized dataset structure and count images\"\"\"\n",
    "    print(f\"Verifying organized dataset at: {organized_path}\")\n",
    "    \n",
    "    for split in ['train', 'validation']:\n",
    "        print(f\"\\nüìä {split.upper()} SET:\")\n",
    "        split_path = os.path.join(organized_path, split)\n",
    "        total_images = 0\n",
    "        \n",
    "        for category in ['Biodegradable', 'Non-Biodegradable']:\n",
    "            category_path = os.path.join(split_path, category)\n",
    "            if os.path.exists(category_path):\n",
    "                count = len([f for f in os.listdir(category_path) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                print(f\"   {category}: {count:,} images\")\n",
    "                total_images += count\n",
    "            else:\n",
    "                print(f\"   ‚ùå {category}: Directory not found\")\n",
    "        \n",
    "        print(f\"   Total {split}: {total_images:,} images\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verify the organized dataset\n",
    "verify_organized_dataset(organized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1803c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Set Up Data Preprocessing and Augmentation\n",
    "# Define image parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create data generators with augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data should only be rescaled (no augmentation)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f'{organized_path}/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    f'{organized_path}/validation',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "print(\"Data generators created successfully!\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.5: Configure PIL for Better Error Handling\n",
    "from PIL import ImageFile\n",
    "import warnings\n",
    "\n",
    "# Allow loading of truncated images (this helps with some corrupted images)\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Suppress warnings for palette images\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='PIL')\n",
    "\n",
    "print(\"‚úÖ PIL configured for robust image loading\")\n",
    "print(\"   - Truncated images will be loaded when possible\")\n",
    "print(\"   - Palette transparency warnings suppressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1365e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.5: Validate and Clean Dataset\n",
    "def validate_and_clean_images(organized_path):\n",
    "    \"\"\"\n",
    "    Validate all images in the organized dataset and remove corrupted ones\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import gc\n",
    "    \n",
    "    print(\"Validating and cleaning dataset...\")\n",
    "    total_removed = 0\n",
    "    \n",
    "    for split in ['train', 'validation']:\n",
    "        for category in ['Biodegradable', 'Non-Biodegradable']:\n",
    "            category_path = os.path.join(organized_path, split, category)\n",
    "            \n",
    "            if os.path.exists(category_path):\n",
    "                print(f\"\\nValidating {split}/{category}...\")\n",
    "                image_files = [f for f in os.listdir(category_path) \n",
    "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                corrupted_files = []\n",
    "                \n",
    "                for i, filename in enumerate(image_files):\n",
    "                    if i % 500 == 0:  # Progress update every 500 files\n",
    "                        print(f\"  Processed {i}/{len(image_files)} images...\")\n",
    "                    \n",
    "                    filepath = os.path.join(category_path, filename)\n",
    "                    \n",
    "                    try:\n",
    "                        # Try to open and verify the image\n",
    "                        with Image.open(filepath) as img:\n",
    "                            # Try to load the image data\n",
    "                            img.load()\n",
    "                            # Verify image has valid dimensions\n",
    "                            if img.size[0] < 10 or img.size[1] < 10:\n",
    "                                corrupted_files.append(filepath)\n",
    "                                continue\n",
    "                            # Try to convert to RGB (this will catch some corruption)\n",
    "                            img.convert('RGB')\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"    Corrupted image found: {filename} - {str(e)}\")\n",
    "                        corrupted_files.append(filepath)\n",
    "                \n",
    "                # Remove corrupted files\n",
    "                for filepath in corrupted_files:\n",
    "                    try:\n",
    "                        os.remove(filepath)\n",
    "                        total_removed += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Error removing {filepath}: {str(e)}\")\n",
    "                \n",
    "                remaining_count = len(image_files) - len(corrupted_files)\n",
    "                print(f\"  ‚úÖ {category}: {remaining_count} valid images (removed {len(corrupted_files)} corrupted)\")\n",
    "                \n",
    "                # Force garbage collection\n",
    "                gc.collect()\n",
    "    \n",
    "    print(f\"\\nüßπ Dataset cleaning completed!\")\n",
    "    print(f\"   Total corrupted images removed: {total_removed}\")\n",
    "    return total_removed\n",
    "\n",
    "# Clean the dataset\n",
    "removed_count = validate_and_clean_images(organized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Create CNN Model Architecture\n",
    "def create_cnn_model():\n",
    "    \"\"\"Create a CNN model for binary classification\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_cnn_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model created and compiled successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ac244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Set Up Training Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Train the Model\n",
    "print(\"Starting model training...\")\n",
    "# Training strategy: Choose epochs based on your time and accuracy requirements\n",
    "# Set EPOCHS based on your needs:\n",
    "# - 5 epochs: Quick test (~3-5 min, 65-75% accuracy)\n",
    "# - 10 epochs: Fast training (~5-10 min, 75-80% accuracy)\n",
    "# - 20 epochs: Balanced approach (~15-20 min, 80-85% accuracy) \n",
    "# - 30 epochs: Good results (~25-30 min, 85-90% accuracy)\n",
    "# - 50 epochs: Better results (~40-50 min, 90-92% accuracy)\n",
    "# - 100 epochs: Maximum results (~80-100 min, 92-95% accuracy)\n",
    "EPOCHS = 30  # Increased for better accuracy - adjust as needed\n",
    "\n",
    "# Calculate steps per epoch for better time estimation\n",
    "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
    "validation_steps = validation_generator.samples // BATCH_SIZE\n",
    "\n",
    "# Add safety checks\n",
    "if steps_per_epoch == 0:\n",
    "    steps_per_epoch = 1\n",
    "if validation_steps == 0:\n",
    "    validation_steps = 1\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "print(f\"Estimated training time: ~{EPOCHS * steps_per_epoch * 2 / 60:.1f} minutes\")\n",
    "print(f\"Note: EarlyStopping may stop training before {EPOCHS} epochs if model stops improving\")\n",
    "print(\"EarlyStopping settings: patience=10 (stops if no improvement for 10 epochs)\")\n",
    "print(f\"üí° Tip: You can change EPOCHS to any value (10, 20, 30, 50, 100+) based on your needs\")\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {str(e)}\")\n",
    "    print(\"\\nüîß Troubleshooting suggestions:\")\n",
    "    print(\"1. Run the dataset cleaning cell again\")\n",
    "    print(\"2. Check if there are any remaining corrupted images\")\n",
    "    print(\"3. Try reducing batch size or image resolution\")\n",
    "    print(\"4. Restart the runtime and try again\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Evaluate the Model\n",
    "print(\"\\nEvaluating model on validation data...\")\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a61013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Plot Training History\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f572b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Generate Predictions and Confusion Matrix\n",
    "print(\"\\nGenerating predictions for confusion matrix...\")\n",
    "validation_generator.reset()\n",
    "predictions = model.predict(validation_generator, verbose=1)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "true_classes = validation_generator.classes\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Save the Model\n",
    "model_save_path = \"/content/waste_model_bio.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"\\nModel saved as: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Create a Test Function\n",
    "def test_single_prediction(model, image_path):\n",
    "    \"\"\"Test model on a single image\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    img = image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    class_names = ['Biodegradable', 'Non-Biodegradable']\n",
    "    predicted_class = class_names[int(prediction > 0.5)]\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    print(f\"Prediction: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Download Model and Create Sample Images\n",
    "# Import files module explicitly to avoid conflicts\n",
    "from google.colab import files as colab_files\n",
    "\n",
    "# Download the model to local system\n",
    "print(\"\\nDownloading model to local system...\")\n",
    "colab_files.download(model_save_path)\n",
    "\n",
    "# Create sample predictions for demo\n",
    "print(\"\\nCreating sample images for demo...\")\n",
    "sample_images_path = \"/content/sample_images\"\n",
    "os.makedirs(sample_images_path, exist_ok=True)\n",
    "\n",
    "# Copy sample images from validation set\n",
    "import random\n",
    "\n",
    "# Use the new class names\n",
    "for class_name in ['Biodegradable', 'Non-Biodegradable']:\n",
    "    class_path = f\"{organized_path}/validation/{class_name}\"\n",
    "    if os.path.exists(class_path):\n",
    "        image_files = os.listdir(class_path)  # Use different variable name to avoid conflict\n",
    "        sample_file = random.choice(image_files)\n",
    "        src = os.path.join(class_path, sample_file)\n",
    "        dst = os.path.join(sample_images_path, f\"sample_{class_name.lower().replace('-', '_')}.jpg\")\n",
    "        shutil.copy2(src, dst)\n",
    "        \n",
    "        # Test prediction on sample\n",
    "        print(f\"\\nTesting on sample {class_name} image:\")\n",
    "        test_single_prediction(model, dst)\n",
    "\n",
    "# Create a zip file with sample images\n",
    "shutil.make_archive(\"/content/sample_images\", 'zip', sample_images_path)\n",
    "colab_files.download(\"/content/sample_images.zip\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final performance summary\n",
    "print(f\"üìä FINAL MODEL PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Validation Accuracy: {val_accuracy:.1%}\")\n",
    "print(f\"   ‚Ä¢ Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"   ‚Ä¢ Training Epochs: {len(history.history['accuracy'])}\")\n",
    "print(f\"   ‚Ä¢ Dataset Size: {train_generator.samples + validation_generator.samples:,} images\")\n",
    "print(f\"   ‚Ä¢ Model Size: ~{os.path.getsize(model_save_path) / (1024*1024):.1f}MB\")\n",
    "\n",
    "print(f\"\\nüì¶ FILES DOWNLOADED:\")\n",
    "print(f\"   1. ü§ñ waste_model_bio.h5 - The trained CNN model\")\n",
    "print(f\"   2. üñºÔ∏è sample_images.zip - Demo images for testing\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS FOR DEPLOYMENT:\")\n",
    "print(f\"   1. Convert model to TensorFlow.js: tensorflowjs_converter\")\n",
    "print(f\"   2. Integrate into your portfolio website\")\n",
    "print(f\"   3. Use sample images for live demo\")\n",
    "print(f\"   4. Deploy to web hosting platform\")\n",
    "\n",
    "print(f\"\\nüíº PORTFOLIO HIGHLIGHTS:\")\n",
    "print(f\"   ‚Ä¢ End-to-end ML pipeline development\")\n",
    "print(f\"   ‚Ä¢ Computer vision and CNN architecture\")\n",
    "print(f\"   ‚Ä¢ Data preprocessing and augmentation\")\n",
    "print(f\"   ‚Ä¢ Model optimization and deployment\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Comprehensive Model Analysis and Review\n",
    "def analyze_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of the trained .h5 model file\n",
    "    \"\"\"\n",
    "    print(\"üîç COMPREHENSIVE MODEL ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Load the saved model\n",
    "        loaded_model = keras.models.load_model(model_path)\n",
    "        print(\"‚úÖ Model loaded successfully!\")\n",
    "        \n",
    "        # 1. Basic Model Information\n",
    "        print(f\"\\nüìä BASIC MODEL INFORMATION:\")\n",
    "        print(f\"   ‚Ä¢ Model Type: {type(loaded_model).__name__}\")\n",
    "        print(f\"   ‚Ä¢ Input Shape: {loaded_model.input_shape}\")\n",
    "        print(f\"   ‚Ä¢ Output Shape: {loaded_model.output_shape}\")\n",
    "        print(f\"   ‚Ä¢ Total Layers: {len(loaded_model.layers)}\")\n",
    "        \n",
    "        # 2. Model Architecture Summary\n",
    "        print(f\"\\nüèóÔ∏è MODEL ARCHITECTURE:\")\n",
    "        loaded_model.summary()\n",
    "        \n",
    "        # 3. Model Size Analysis\n",
    "        import os\n",
    "        model_size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        print(f\"\\nüíæ MODEL SIZE ANALYSIS:\")\n",
    "        print(f\"   ‚Ä¢ File Size: {model_size_mb:.2f} MB\")\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = loaded_model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(w) for w in loaded_model.trainable_weights])\n",
    "        non_trainable_params = total_params - trainable_params\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Total Parameters: {total_params:,}\")\n",
    "        print(f\"   ‚Ä¢ Trainable Parameters: {trainable_params:,}\")\n",
    "        print(f\"   ‚Ä¢ Non-trainable Parameters: {non_trainable_params:,}\")\n",
    "        print(f\"   ‚Ä¢ Memory Usage (approx): {total_params * 4 / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # 4. Layer Analysis\n",
    "        print(f\"\\nüî¨ DETAILED LAYER ANALYSIS:\")\n",
    "        conv_layers = 0\n",
    "        dense_layers = 0\n",
    "        dropout_layers = 0\n",
    "        batch_norm_layers = 0\n",
    "        \n",
    "        for i, layer in enumerate(loaded_model.layers):\n",
    "            layer_type = type(layer).__name__\n",
    "            if 'Conv' in layer_type:\n",
    "                conv_layers += 1\n",
    "            elif 'Dense' in layer_type:\n",
    "                dense_layers += 1\n",
    "            elif 'Dropout' in layer_type:\n",
    "                dropout_layers += 1\n",
    "            elif 'BatchNormalization' in layer_type:\n",
    "                batch_norm_layers += 1\n",
    "            \n",
    "            # Print first few and last few layers\n",
    "            if i < 5 or i >= len(loaded_model.layers) - 3:\n",
    "                output_shape = str(layer.output_shape) if hasattr(layer, 'output_shape') else 'N/A'\n",
    "                print(f\"   Layer {i+1}: {layer_type} - {output_shape}\")\n",
    "            elif i == 5:\n",
    "                print(\"   ... (middle layers omitted)\")\n",
    "        \n",
    "        print(f\"\\nüìà LAYER STATISTICS:\")\n",
    "        print(f\"   ‚Ä¢ Convolutional Layers: {conv_layers}\")\n",
    "        print(f\"   ‚Ä¢ Dense Layers: {dense_layers}\")\n",
    "        print(f\"   ‚Ä¢ Dropout Layers: {dropout_layers}\")\n",
    "        print(f\"   ‚Ä¢ Batch Normalization Layers: {batch_norm_layers}\")\n",
    "        \n",
    "        # 5. Model Compilation Information\n",
    "        print(f\"\\n‚öôÔ∏è COMPILATION SETTINGS:\")\n",
    "        print(f\"   ‚Ä¢ Optimizer: {loaded_model.optimizer.__class__.__name__}\")\n",
    "        print(f\"   ‚Ä¢ Loss Function: {loaded_model.loss}\")\n",
    "        print(f\"   ‚Ä¢ Metrics: {loaded_model.metrics_names}\")\n",
    "        \n",
    "        # 6. Test Model Prediction Function\n",
    "        print(f\"\\nüß™ MODEL TESTING:\")\n",
    "        \n",
    "        def test_model_prediction():\n",
    "            # Create a dummy input to test the model\n",
    "            dummy_input = np.random.rand(1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "            prediction = loaded_model.predict(dummy_input, verbose=0)\n",
    "            return prediction[0][0]\n",
    "        \n",
    "        test_pred = test_model_prediction()\n",
    "        predicted_class = \"Non-Biodegradable\" if test_pred > 0.5 else \"Biodegradable\"\n",
    "        confidence = test_pred if test_pred > 0.5 else 1 - test_pred\n",
    "        \n",
    "        print(f\"   ‚úÖ Model prediction test successful!\")\n",
    "        print(f\"   üìä Test prediction: {predicted_class} ({confidence:.1%} confidence)\")\n",
    "        \n",
    "        # 7. Model Validation\n",
    "        print(f\"\\n‚úÖ MODEL VALIDATION SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Model loads correctly: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ Architecture is intact: ‚úÖ\") \n",
    "        print(f\"   ‚Ä¢ Can make predictions: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ Binary classification setup: ‚úÖ\")\n",
    "        print(f\"   ‚Ä¢ Ready for deployment: ‚úÖ\")\n",
    "        \n",
    "        # 8. Performance Summary from Training\n",
    "        if 'val_accuracy' in locals():\n",
    "            print(f\"\\nüèÜ FINAL PERFORMANCE:\")\n",
    "            print(f\"   ‚Ä¢ Validation Accuracy: {val_accuracy:.1%}\")\n",
    "            print(f\"   ‚Ä¢ Validation Loss: {val_loss:.4f}\")\n",
    "            print(f\"   ‚Ä¢ Model Quality: {'üåü EXCELLENT' if val_accuracy > 0.9 else 'ü•á GOOD' if val_accuracy > 0.8 else 'ü•à FAIR'}\")\n",
    "        \n",
    "        return loaded_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Analyze the trained model\n",
    "print(\"Starting comprehensive model analysis...\")\n",
    "analyzed_model = analyze_trained_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 18: Visual Model Inspection and Performance Visualization\n",
    "def create_model_visualization(model, history=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive visual analysis of the model\n",
    "    \"\"\"\n",
    "    print(\"üìä CREATING MODEL VISUALIZATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Model Architecture Visualization\n",
    "    try:\n",
    "        print(\"üé® Generating model architecture plot...\")\n",
    "        tf.keras.utils.plot_model(\n",
    "            model, \n",
    "            to_file='model_architecture.png',\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            rankdir='TB',\n",
    "            expand_nested=False,\n",
    "            dpi=96\n",
    "        )\n",
    "        print(\"‚úÖ Model architecture saved as 'model_architecture.png'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create architecture plot: {e}\")\n",
    "    \n",
    "    # 2. Model Weights Analysis\n",
    "    print(f\"\\n‚öñÔ∏è WEIGHTS ANALYSIS:\")\n",
    "    layer_weights_info = []\n",
    "    \n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if layer.weights:\n",
    "            weights = layer.get_weights()\n",
    "            if weights:\n",
    "                weight_stats = {\n",
    "                    'layer_name': layer.name,\n",
    "                    'layer_type': type(layer).__name__,\n",
    "                    'weight_shapes': [w.shape for w in weights],\n",
    "                    'weight_means': [np.mean(w) for w in weights],\n",
    "                    'weight_stds': [np.std(w) for w in weights],\n",
    "                    'weight_mins': [np.min(w) for w in weights],\n",
    "                    'weight_maxs': [np.max(w) for w in weights]\n",
    "                }\n",
    "                layer_weights_info.append(weight_stats)\n",
    "                \n",
    "                print(f\"   Layer {i+1} ({layer.name}):\")\n",
    "                print(f\"      Type: {weight_stats['layer_type']}\")\n",
    "                print(f\"      Shapes: {weight_stats['weight_shapes']}\")\n",
    "                print(f\"      Mean weights: {[f'{m:.4f}' for m in weight_stats['weight_means']]}\")\n",
    "                print(f\"      Std weights: {[f'{s:.4f}' for s in weight_stats['weight_stds']]}\")\n",
    "    \n",
    "    # 3. Performance Metrics Visualization\n",
    "    if history is not None:\n",
    "        print(f\"\\nüìà CREATING PERFORMANCE PLOTS...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        axes[0,0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "        axes[0,0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "        axes[0,0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "        axes[0,0].set_xlabel('Epoch')\n",
    "        axes[0,0].set_ylabel('Accuracy')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss plot\n",
    "        axes[0,1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "        axes[0,1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "        axes[0,1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
    "        axes[0,1].set_xlabel('Epoch')\n",
    "        axes[0,1].set_ylabel('Loss')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Learning rate plot (if available)\n",
    "        if 'learning_rate' in history.history:\n",
    "            axes[1,0].plot(history.history['learning_rate'], linewidth=2, color='orange')\n",
    "            axes[1,0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "            axes[1,0].set_xlabel('Epoch')\n",
    "            axes[1,0].set_ylabel('Learning Rate')\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, 'Learning Rate\\nData Not Available', \n",
    "                          ha='center', va='center', transform=axes[1,0].transAxes)\n",
    "        \n",
    "        # Final metrics summary\n",
    "        final_train_acc = history.history['accuracy'][-1]\n",
    "        final_val_acc = history.history['val_accuracy'][-1]\n",
    "        final_train_loss = history.history['loss'][-1]\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        \n",
    "        metrics_text = f\"\"\"FINAL METRICS\n",
    "        \n",
    "Training Accuracy: {final_train_acc:.1%}\n",
    "Validation Accuracy: {final_val_acc:.1%}\n",
    "Training Loss: {final_train_loss:.4f}\n",
    "Validation Loss: {final_val_loss:.4f}\n",
    "\n",
    "Epochs Trained: {len(history.history['accuracy'])}\n",
    "Overfitting Gap: {abs(final_train_acc - final_val_acc):.1%}\"\"\"\n",
    "        \n",
    "        axes[1,1].text(0.1, 0.5, metrics_text, transform=axes[1,1].transAxes, \n",
    "                      fontsize=12, verticalalignment='center',\n",
    "                      bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "        axes[1,1].set_title('Training Summary', fontsize=14, fontweight='bold')\n",
    "        axes[1,1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Performance visualization complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No training history available for performance plots\")\n",
    "    \n",
    "    return layer_weights_info\n",
    "\n",
    "# 4. Model Comparison and Benchmarking\n",
    "def benchmark_model_performance(model):\n",
    "    \"\"\"\n",
    "    Benchmark the model against common standards\n",
    "    \"\"\"\n",
    "    print(f\"\\nüèÅ MODEL BENCHMARKING:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Size benchmarking\n",
    "    model_size_mb = os.path.getsize(model_save_path) / (1024 * 1024)\n",
    "    print(f\"üìè SIZE ANALYSIS:\")\n",
    "    if model_size_mb < 10:\n",
    "        print(f\"   ‚Ä¢ Size: {model_size_mb:.1f}MB - üü¢ Excellent (Mobile-friendly)\")\n",
    "    elif model_size_mb < 50:\n",
    "        print(f\"   ‚Ä¢ Size: {model_size_mb:.1f}MB - üü° Good (Web-friendly)\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Size: {model_size_mb:.1f}MB - üü† Large (Consider optimization)\")\n",
    "    \n",
    "    # Parameter benchmarking\n",
    "    total_params = model.count_params()\n",
    "    print(f\"\\nüî¢ PARAMETER ANALYSIS:\")\n",
    "    if total_params < 1_000_000:\n",
    "        print(f\"   ‚Ä¢ Parameters: {total_params:,} - üü¢ Lightweight\")\n",
    "    elif total_params < 10_000_000:\n",
    "        print(f\"   ‚Ä¢ Parameters: {total_params:,} - üü° Medium\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Parameters: {total_params:,} - üü† Heavy\")\n",
    "    \n",
    "    # Architecture benchmarking\n",
    "    print(f\"\\nüèóÔ∏è ARCHITECTURE ASSESSMENT:\")\n",
    "    conv_layers = sum(1 for layer in model.layers if 'conv' in layer.name.lower())\n",
    "    dense_layers = sum(1 for layer in model.layers if 'dense' in layer.name.lower())\n",
    "    dropout_layers = sum(1 for layer in model.layers if 'dropout' in layer.name.lower())\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Conv Layers: {conv_layers} - {'üü¢ Good depth' if conv_layers >= 4 else 'üü° Light'}\")\n",
    "    print(f\"   ‚Ä¢ Dense Layers: {dense_layers} - {'üü¢ Good' if dense_layers >= 2 else 'üü° Simple'}\")\n",
    "    print(f\"   ‚Ä¢ Regularization: {'üü¢ Well regularized' if dropout_layers >= 2 else 'üü° Basic'}\")\n",
    "    \n",
    "    # Overall rating\n",
    "    if 'val_accuracy' in locals() and val_accuracy > 0.95:\n",
    "        rating = \"üåü OUTSTANDING\"\n",
    "    elif 'val_accuracy' in locals() and val_accuracy > 0.90:\n",
    "        rating = \"ü•á EXCELLENT\"\n",
    "    elif 'val_accuracy' in locals() and val_accuracy > 0.85:\n",
    "        rating = \"ü•à VERY GOOD\"\n",
    "    else:\n",
    "        rating = \"ü•â GOOD\"\n",
    "    \n",
    "    print(f\"\\nüèÜ OVERALL MODEL RATING: {rating}\")\n",
    "    \n",
    "    return {\n",
    "        'size_mb': model_size_mb,\n",
    "        'total_params': total_params,\n",
    "        'conv_layers': conv_layers,\n",
    "        'dense_layers': dense_layers,\n",
    "        'dropout_layers': dropout_layers\n",
    "    }\n",
    "\n",
    "# Run comprehensive model analysis\n",
    "if 'analyzed_model' in locals() and analyzed_model is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    weights_info = create_model_visualization(analyzed_model, history if 'history' in locals() else None)\n",
    "    benchmark_results = benchmark_model_performance(analyzed_model)\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please run the model analysis cell first!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
